#!/usr/bin/env python3
"""
convert_images_to_h.py

Scan an input folder for images, resize/crop them to the target resolution,
convert to the requested mode (rgb565 or 1-bit monochrome) and write a .h
file per image containing a C array (and a small index header).

Usage examples:
  python tools/convert_images_to_h.py --input images --output out --width 240 --height 320
  python tools/convert_images_to_h.py -i imgs -o generated -W 128 -H 64 --mode mono --progmem

Produces per-image headers and `images_index.h` in the output folder.
"""

from PIL import Image
import os
import argparse
import re


def sanitize_name(name: str) -> str:
    name = re.sub(r"[^0-9a-zA-Z_]", "_", name)
    if re.match(r"^[0-9]", name):
        name = "_" + name
    return name


def find_content_bbox(img: Image.Image, edge_thresh: int = 30, min_area_frac: float = 0.005):
    """Return a bounding box (x0,y0,x1,y1) of the visually salient/content area.
    Uses edge detection and a threshold to find a content bbox. Returns None
    if no significant content is detected (caller can fallback to center-crop).
    """
    try:
        from PIL import ImageFilter, ImageOps
    except Exception:
        return None

    gray = img.convert("L")
    edges = gray.filter(ImageFilter.FIND_EDGES)
    # increase contrast on edges so thresholding is more reliable
    edges = ImageOps.autocontrast(edges)
    bw = edges.point(lambda p: 255 if p > edge_thresh else 0)
    bbox = bw.getbbox()
    if not bbox:
        return None
    x0, y0, x1, y1 = bbox
    area = (x1 - x0) * (y1 - y0)
    img_area = img.size[0] * img.size[1]
    if area < img_area * min_area_frac:
        # too small to be trustworthy
        return None
    return (x0, y0, x1, y1)


def rgb565_from_rgb(r, g, b):
    return ((r & 0xF8) << 8) | ((g & 0xFC) << 3) | (b >> 3)


def pack_monochrome(img: Image.Image):
    """Pack 1-bit pixels into bytes, MSB first for leftmost pixel."""
    bw = img.convert("1")
    pixels = bw.getdata()
    out = bytearray()
    byte = 0
    bit = 7
    for p in pixels:
        bit_val = 0 if p else 1
        byte |= (bit_val << bit)
        bit -= 1
        if bit < 0:
            out.append(byte)
            byte = 0
            bit = 7
    if bit != 7:
        out.append(byte)
    return bytes(out)


def write_header_rgb565(out_path, base_name, w, h, data, progmem=False):
    guard = f"_{base_name.upper()}_H_"
    arr_name = f"{base_name}_data"
    with open(out_path, "w", newline="\n") as f:
        f.write(f"// Generated by convert_images_to_h.py\n")
        f.write(f"#ifndef {guard}\n")
        f.write(f"#define {guard}\n\n")
        if progmem:
            f.write("#include <avr/pgmspace.h>\n\n")
        f.write(f"#include <stdint.h>\n\n")
        f.write(f"#define {base_name.upper()}_WIDTH {w}\n")
        f.write(f"#define {base_name.upper()}_HEIGHT {h}\n\n")
        pm = " PROGMEM" if progmem else ""
        f.write(f"const uint16_t {arr_name}[]{pm} = {{\n")
        for i, v in enumerate(data):
            sep = "\n" if (i + 1) % 12 == 0 else " "
            f.write(f"0x{v:04X}," + sep)
        f.write("\n};\n\n")
        f.write(f"#endif // {guard}\n")


def write_header_mono(out_path, base_name, w, h, data_bytes, progmem=False):
    guard = f"_{base_name.upper()}_H_"
    arr_name = f"{base_name}_data"
    with open(out_path, "w", newline="\n") as f:
        f.write(f"// Generated by convert_images_to_h.py\n")
        f.write(f"#ifndef {guard}\n")
        f.write(f"#define {guard}\n\n")
        if progmem:
            f.write("#include <avr/pgmspace.h>\n\n")
        f.write(f"#include <stdint.h>\n\n")
        f.write(f"#define {base_name.upper()}_WIDTH {w}\n")
        f.write(f"#define {base_name.upper()}_HEIGHT {h}\n\n")
        pm = " PROGMEM" if progmem else ""
        f.write(f"const uint8_t {arr_name}[]{pm} = {{\n")
        for i, b in enumerate(data_bytes):
            sep = "\n" if (i + 1) % 16 == 0 else " "
            f.write(f"0x{b:02X}," + sep)
        f.write("\n};\n\n")
        f.write(f"#endif // {guard}\n")


def generate_index(out_dir, images, mode, progmem=False):
    out_path = os.path.join(out_dir, "images_index.h")
    with open(out_path, "w", newline="\n") as f:
        f.write("// images_index.h - generated by convert_images_to_h.py\n")
        f.write("#pragma once\n\n")
        f.write("#include <stdint.h>\n\n")
        for im in images:
            fname = im['header']
            f.write(f"#include \"{os.path.basename(fname)}\"\n")
        f.write("\n")
        if mode == "rgb565":
            f.write("typedef struct { const uint16_t* data; uint16_t w; uint16_t h; } ImageRGB565;\n\n")
            f.write(f"static const ImageRGB565 images[] = {{\n")
            for im in images:
                arr = f"{im['name']}_data"
                f.write(f"  {{ {arr}, {im['w']}, {im['h']} }},\n")
            f.write("};\n\n")
            f.write(f"#define IMAGE_COUNT (sizeof(images)/sizeof(images[0]))\n")
        elif mode == "mono":
            f.write("typedef struct { const uint8_t* data; uint16_t w; uint16_t h; } ImageMono;\n\n")
            f.write(f"static const ImageMono images[] = {{\n")
            for im in images:
                arr = f"{im['name']}_data"
                f.write(f"  {{ {arr}, {im['w']}, {im['h']} }},\n")
            f.write("};\n\n")
            f.write(f"#define IMAGE_COUNT (sizeof(images)/sizeof(images[0]))\n")
        elif mode == "tri":
            f.write("typedef struct { const uint8_t* black; const uint8_t* red; uint16_t w; uint16_t h; } ImageTri;\n\n")
            f.write(f"static const ImageTri images[] = {{\n")
            for im in images:
                arr_b = f"{im['name']}_black"
                arr_r = f"{im['name']}_red"
                f.write(f"  {{ {arr_b}, {arr_r}, {im['w']}, {im['h']} }},\n")
            f.write("};\n\n")
            f.write(f"#define IMAGE_COUNT (sizeof(images)/sizeof(images[0]))\n")
        else:
            f.write("#error \"Unsupported mode for index generation\"\n")


def process_image(path, out_dir, width, height, mode, progmem=False, focus="none", focus_margin=1.8, top_margin=20):
    img = Image.open(path)
    # Aspect-preserving resize with optional face-focus crop
    src_w, src_h = img.size
    target_ratio = width / height

    face_box = None
    person_box = None
    if focus == "person":
        try:
            import cv2
            import numpy as np
            img_rgb = np.array(img.convert('RGB'))
            hog = cv2.HOGDescriptor()
            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
            rects, weights = hog.detectMultiScale(img_rgb, winStride=(8, 8), padding=(8, 8), scale=1.05)
            if len(rects) > 0:
                # choose largest person bbox
                rects = sorted(rects, key=lambda r: r[2] * r[3], reverse=True)
                (px, py, pw, ph) = rects[0]
                person_box = (int(px), int(py), int(pw), int(ph))
                # try detect face inside person bbox
                try:
                    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)
                    cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                    rx, ry, rw, rh = person_box
                    roi = gray[ry:ry+rh, rx:rx+rw]
                    faces = cascade.detectMultiScale(roi, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))
                    if len(faces) > 0:
                        faces = sorted(faces, key=lambda r: r[2] * r[3], reverse=True)
                        (fx, fy, fw, fh) = faces[0]
                        # convert to global coords
                        face_box = (int(rx + fx), int(ry + fy), int(fw), int(fh))
                except Exception:
                    face_box = None
        except Exception:
            person_box = None

    if focus == "face":
        try:
            import cv2
            import numpy as np
            # detect faces on a grayscale copy
            gray = cv2.cvtColor(np.array(img.convert('RGB')), cv2.COLOR_RGB2GRAY)
            cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
            if len(faces) > 0:
                faces = sorted(faces, key=lambda r: r[2] * r[3], reverse=True)
                (fx, fy, fw, fh) = faces[0]
                face_box = (fx, fy, fw, fh)
        except Exception:
            face_box = None

    if face_box:
        fx, fy, fw, fh = face_box
        face_cx = fx + fw // 2
        face_cy = fy + fh // 2
        margin = focus_margin
        req_w = fw * margin
        req_h = fh * margin
        if (req_w / req_h) > target_ratio:
            crop_w = int(min(req_w, src_w))
            crop_h = int(crop_w / target_ratio)
        else:
            crop_h = int(min(req_h, src_h))
            crop_w = int(crop_h * target_ratio)
        crop_w = min(crop_w, src_w)
        crop_h = min(crop_h, src_h)
        left = int(max(0, min(src_w - crop_w, face_cx - crop_w // 2)))
        top = int(max(0, min(src_h - crop_h, face_cy - crop_h // 2)))
        img = img.crop((left, top, left + crop_w, top + crop_h))
    elif focus == "person" and person_box is not None:
        # Use HOG-person bbox plus detected face to center crop. Ensure whole person is visible
        rx, ry, rw, rh = person_box
        req_left = rx
        req_right = rx + rw
        req_top = max(0, ry - top_margin)
        req_bottom = ry + rh

        # prefer face center if available, else approximate near upper body
        if face_box:
            fx, fy, fw, fh = face_box
            cx = fx + fw / 2.0
            cy = fy + fh / 2.0
        else:
            cx = rx + rw / 2.0
            cy = ry + rh * 0.25

        # minimal half-sizes to include required bbox when centered at (cx,cy)
        hw_min = max(cx - req_left, req_right - cx)
        hh_min = max(cy - req_top, req_bottom - cy)
        hw_min = max(hw_min, 1.0)
        hh_min = max(hh_min, 1.0)

        # adjust to aspect ratio (keep crop_w / crop_h == target_ratio)
        if (2.0 * hw_min) / (2.0 * hh_min) > target_ratio:
            hh_min = hw_min / target_ratio
        else:
            hw_min = hh_min * target_ratio

        # maximum half-sizes allowed centered at (cx,cy)
        hw_max = min(cx, src_w - cx)
        hh_max = min(cy, src_h - cy)
        # scaling factor to expand as much as possible
        s = 1.0
        if hw_min > 0 and hh_min > 0:
            s = min(hw_max / hw_min, hh_max / hh_min)
            if s < 1.0:
                s = 1.0

        hw = int(max(1, hw_min * s))
        hh = int(max(1, hh_min * s))

        crop_w = min(int(2 * hw), src_w)
        crop_h = min(int(2 * hh), src_h)

        # center crop on (cx,cy)
        left = int(cx - crop_w // 2)
        left = max(0, min(left, src_w - crop_w))
        top = int(cy - crop_h // 2)
        top = max(0, min(top, src_h - crop_h))

        # Ensure at least top_margin pixels above the head/person top
        if face_box:
            head_y = face_box[1]
        else:
            head_y = ry
        if (head_y - top) < top_margin:
            top = max(0, head_y - top_margin)
            top = max(0, min(top, src_h - crop_h))

        img = img.crop((left, top, left + crop_w, top + crop_h))
    else:
        src_w, src_h = img.size
        # Try a lightweight content-aware crop when not explicitly using face focus.
        bbox = None
        if focus != "face":
            try:
                bbox = find_content_bbox(img, edge_thresh=35, min_area_frac=0.004)
            except Exception:
                bbox = None

        if bbox:
            x0, y0, x1, y1 = bbox
            bw = x1 - x0
            bh = y1 - y0
            pad = 0.06
            cx = x0 + bw / 2.0
            cy = y0 + bh / 2.0
            new_w = bw * (1.0 + pad)
            new_h = bh * (1.0 + pad)
            # Expand to match target aspect ratio
            if (new_w / new_h) > target_ratio:
                new_h = new_w / target_ratio
            else:
                new_w = new_h * target_ratio
            new_w = min(new_w, src_w)
            new_h = min(new_h, src_h)
            left = int(max(0, min(src_w - new_w, cx - new_w / 2.0)))
            top = int(max(0, min(src_h - new_h, cy - new_h / 2.0)))
            img = img.crop((left, top, left + int(new_w), top + int(new_h)))
        else:
            # fallback: center-crop to target aspect ratio
            src_ratio = src_w / src_h
            if src_ratio > target_ratio:
                new_h = src_h
                new_w = int(src_h * target_ratio)
            else:
                new_w = src_w
                new_h = int(src_w / target_ratio)
            left = (src_w - new_w) // 2
            top = (src_h - new_h) // 2
            img = img.crop((left, top, left + new_w, top + new_h))

    img = img.resize((width, height), Image.LANCZOS)

    # Ensure background is white for images with transparency
    if img.mode in ("RGBA", "LA") or (img.mode == "P" and "transparency" in img.info):
        bg = Image.new("RGBA", img.size, (255, 255, 255, 255))
        bg.paste(img, (0, 0), img.convert("RGBA"))
        img = bg.convert("RGB")
    else:
        img = img.convert("RGB")

    base = os.path.splitext(os.path.basename(path))[0]
    base = sanitize_name(base)
    header_name = f"{base}.h"
    out_header = os.path.join(out_dir, header_name)

    if mode == "rgb565":
        rgb = img.convert("RGB")
        data = [rgb565_from_rgb(r, g, b) for (r, g, b) in rgb.getdata()]
        write_header_rgb565(out_header, base, width, height, data, progmem=progmem)
    elif mode == "mono":
        mono_bytes = pack_monochrome(img)
        write_header_mono(out_header, base, width, height, mono_bytes, progmem=progmem)
    else:
        # tri-color output: produce two 1-bit planes: black mask and red mask
        from PIL import ImageFilter
        import colorsys

        rgb = img.convert("RGB")
        w, h = rgb.size

        # edge map used to preserve outlines and avoid demoting edge pixels
        from PIL import ImageFilter
        edges = rgb.convert("L").filter(ImageFilter.FIND_EDGES)
        edge_pixels = list(edges.getdata())

        # We'll output two 1-bit planes: black mask and red mask.
        # Red has priority (when red detected, mark red and avoid black underneath).
        pixels = list(rgb.getdata())
        total_px = w * h
        black_bits = [0] * total_px
        red_bits = [0] * total_px
        luma = [0.0] * total_px

        # thresholds (tweakable)
        white_luma_thresh = 240   # above this luminance -> force white
        red_sat_thresh = 0.20     # saturation above this -> candidate for red
        red_v_thresh = 0.18       # value/brightness threshold for red detection
        edge_thresh = 50          # edge pixel brightness above which we consider an edge
        black_luma_thresh = 90    # below this luminance -> candidate for black

        for i, (r, g, b) in enumerate(pixels):
            l = 0.299 * r + 0.587 * g + 0.114 * b
            luma[i] = l
            # prefer white if very bright
            if l >= white_luma_thresh:
                continue

            # detect red via HSV
            rf, gf, bf = r / 255.0, g / 255.0, b / 255.0
            h_val, s_val, v_val = colorsys.rgb_to_hsv(rf, gf, bf)
            is_red_hue = (h_val < 0.06) or (h_val > 0.94)
            if s_val > red_sat_thresh and v_val > red_v_thresh and is_red_hue and r > 90:
                red_bits[i] = 1
                continue

            # otherwise mark black if dark enough or strong edge
            if l < black_luma_thresh or edge_pixels[i] >= edge_thresh:
                black_bits[i] = 1

        # Ensure no overlap: red wins
        for i in range(total_px):
            if red_bits[i]:
                black_bits[i] = 0

        # Post-adjustment: prefer white. If too many black pixels, demote some
        # non-edge blacks to white (starting from less-dark ones) until target reached.
        desired_white_frac = 0.60
        def counts_bw():
            black_c = sum(1 for k in range(total_px) if black_bits[k])
            red_c = sum(1 for k in range(total_px) if red_bits[k])
            white_c = total_px - black_c - red_c
            return white_c, red_c, black_c

        white_c, red_c, black_c = counts_bw()
        if (white_c / float(total_px)) < desired_white_frac:
            need = int(desired_white_frac * total_px) - white_c
            # choose black pixels with luma closer to white and low edge response
            candidates = [k for k in range(total_px) if black_bits[k] and edge_pixels[k] < edge_thresh]
            candidates.sort(key=lambda k: luma[k], reverse=True)
            for k in candidates[:need]:
                black_bits[k] = 0

        # If red is not more frequent than black, promote red candidates
        if red_c <= black_c:
            try:
                import colorsys as _colorsys
                candidates = []
                for k, (r, g, b) in enumerate(pixels):
                    if red_bits[k] == 0 and black_bits[k] == 1 and edge_pixels[k] < edge_thresh:
                        rf, gf, bf = r / 255.0, g / 255.0, b / 255.0
                        h_val, s_val, v_val = _colorsys.rgb_to_hsv(rf, gf, bf)
                        is_red_hue = (h_val < 0.06) or (h_val > 0.94)
                        if s_val > (red_sat_thresh * 0.8) and v_val > red_v_thresh and is_red_hue and r > 90:
                            candidates.append(k)
                promote_goal = max(0, black_c - red_c + 1)
                for k in candidates[:promote_goal]:
                    red_bits[k] = 1
                    black_bits[k] = 0
            except Exception:
                pass

        # pack black bits (1 bit per pixel, MSB-first)
        black_bytes = bytearray()
        byte = 0
        bit = 7
        for v in black_bits:
            byte |= ((v & 1) << bit)
            bit -= 1
            if bit < 0:
                black_bytes.append(byte)
                byte = 0
                bit = 7
        if bit != 7:
            black_bytes.append(byte)

        # pack red bits (1 bit per pixel, MSB-first)
        red_bytes = bytearray()
        byte = 0
        bit = 7
        for v in red_bits:
            byte |= ((v & 1) << bit)
            bit -= 1
            if bit < 0:
                red_bytes.append(byte)
                byte = 0
                bit = 7
        if bit != 7:
            red_bytes.append(byte)

        # write header containing black plane and red mask (1bpp each)
        guard = f"_{base.upper()}_H_"
        arr_black = f"{base}_black"
        arr_red = f"{base}_red"
        with open(out_header, "w", newline="\n") as f:
            f.write("// Generated by convert_images_to_h.py (tri-color: black + red masks)\n")
            f.write(f"#ifndef {guard}\n")
            f.write(f"#define {guard}\n\n")
            if progmem:
                f.write("#include <avr/pgmspace.h>\n\n")
            f.write("#include <stdint.h>\n\n")
            f.write(f"#define {base.upper()}_WIDTH {width}\n")
            f.write(f"#define {base.upper()}_HEIGHT {height}\n\n")
            pm = " PROGMEM" if progmem else ""
            f.write(f"const uint8_t {arr_black}[]{pm} = {{\n")
            for i, b in enumerate(black_bytes):
                sep = "\n" if (i + 1) % 16 == 0 else " "
                f.write(f"0x{b:02X}," + sep)
            f.write("\n};\n\n")
            f.write(f"const uint8_t {arr_red}[]{pm} = {{\n")
            for i, b in enumerate(red_bytes):
                sep = "\n" if (i + 1) % 16 == 0 else " "
                f.write(f"0x{b:02X}," + sep)
            f.write("\n};\n\n")
            f.write(f"#endif // {guard}\n")

    return { 'name': base, 'header': out_header, 'w': width, 'h': height }


def main():
    p = argparse.ArgumentParser(description="Convert images to C headers for embedded displays")
    p.add_argument("-i", "--input", default="images", help="Input folder with images")
    p.add_argument("-o", "--output", default="out", help="Output folder for .h files")
    p.add_argument("-W", "--width", type=int, required=True, help="Target width")
    p.add_argument("-H", "--height", type=int, required=True, help="Target height")
    p.add_argument("-m", "--mode", choices=["rgb565", "mono", "tri"], default="rgb565", help="Output pixel format")
    p.add_argument("--progmem", action="store_true", help="Emit PROGMEM for AVR/AVR-GCC")
    p.add_argument("--focus", choices=["none", "face", "person"], default="none", help="Focus/crop on detected face or person to avoid background-heavy crops (requires opencv)")
    p.add_argument("--focus-margin", type=float, default=1.8, help="Multiplier around detected face to include when focusing (larger = less zoom)")
    p.add_argument("--top-margin", type=int, default=20, help="Top margin in pixels above detected head when using person focus")
    args = p.parse_args()

    if not os.path.isdir(args.input):
        raise SystemExit(f"Input folder not found: {args.input}")
    os.makedirs(args.output, exist_ok=True)

    images = []
    for fname in sorted(os.listdir(args.input)):
        path = os.path.join(args.input, fname)
        if not os.path.isfile(path):
            continue
        try:
            im = Image.open(path)
            im.close()
        except Exception:
            continue
        print(f"Processing: {fname}")
        info = process_image(path, args.output, args.width, args.height, args.mode, progmem=args.progmem, focus=args.focus, focus_margin=args.focus_margin, top_margin=args.top_margin)
        images.append(info)

    if images:
        generate_index(args.output, images, args.mode, progmem=args.progmem)
        print(f"Wrote {len(images)} headers + images_index.h to {args.output}")
    else:
        print("No images processed.")


if __name__ == '__main__':
    main()
